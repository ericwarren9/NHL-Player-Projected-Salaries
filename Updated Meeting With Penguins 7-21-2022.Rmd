---
title: "Updated Meeting With the Penguins"
author: "Eric Warren and Hailey Jensen"
date: '2022-07-21'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE,
                      fig.width=14, 
                      fig.height=9)
```

```{r load in}
library(tidyverse)
salaryAllSeasons <- read_csv("UsedDataForProject/NHL Player Stats and Salary Per 60 Minutes and Standardized 2019-22.csv")
```

## Statistical EDA Modeling Updated {.tabset}

### Initial Analysis

Here we wanted to show the number of games being played by players to quickly discuss this. We thought going with a 20 game minimum was the best idea for analysis.
```{r games}
salaryAllSeasons %>%
  ggplot(aes(x = games_played)) +
  stat_bin(binwidth = 5,
                 geom="text", 
                 aes(label=after_stat(count)), 
                 vjust=0) +
  theme_bw()

salaryAllSeasons %>%
  ggplot(aes(x = games_played)) + 
  stat_ecdf() +
  theme_bw()
```

### PCA

We did Principal Component Analysis to show if any variables stand out more than others.

We wanted to show with elbow plot that not many components were really needed. Note we took out the "Entry Level Contract" type and filtered that players must have played 20 games
```{r pca elbow plot}
library(stats)
# Change to dummy data set
salaryAllSeasonsUpdated <- salaryAllSeasons %>%
  filter(games_played >= 20,
         type != "Entry_Level")
# Change to factor data from character
salaryAllSeasonsUpdated[sapply(salaryAllSeasonsUpdated, is.character)] <- lapply(salaryAllSeasonsUpdated[sapply(salaryAllSeasonsUpdated, is.character)], as.factor)
# Change to numeric data
salaryAllSeasonsUpdated[sapply(salaryAllSeasonsUpdated, is.factor)] <- lapply(salaryAllSeasonsUpdated[sapply(salaryAllSeasonsUpdated, is.factor)], as.numeric)
# Omit na's
salaryAllSeasonsUpdated <- salaryAllSeasonsUpdated %>%
  na.omit()
# Make models
model_CAPHIT <- as.matrix(select(salaryAllSeasonsUpdated, -cap_hit))
# Only use variables that don't have zero variance
model_CAPHIT <- model_CAPHIT[ , which(apply(model_CAPHIT, 2, var) != 0)]
pca_CAPHIT <- prcomp(model_CAPHIT, center = T, scale. = T)

# Make an elbow plot
library(broom)
pca_CAPHIT %>%
  tidy(matrix = "eigenvalues") %>%
  ggplot(aes(x = PC,
             y = percent)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 1 / ncol(model_CAPHIT),
             color = "cornflowerblue",
             linetype = "dashed") +
  theme_bw()
```

We then wanted to see in the first two components what variables had the most weight as this could help us in our reduction methods.
```{r pca vectors}
# Look at what vectors have the most impact
arrow_style <- arrow(
  angle = 20, ends = "first", type = "closed", 
  length = grid::unit(8, "pt")
)
library(ggrepel)
pca_CAPHIT %>%
  tidy(matrix = "rotation") %>%
  pivot_wider(names_from = "PC", names_prefix = "PC", 
              values_from = "value") %>%
  mutate(stat_type = ifelse(str_detect(column, "all"), "all",
                            ifelse(str_detect(column, "5on4"), "5on4",
                                   ifelse(str_detect(column, "4on5"), "4on5", 
                                          ifelse(str_detect(column, "5on5"), "5on5", "category"))))) %>%
  ggplot(aes(PC1, PC2)) +
  geom_segment(xend = 0, yend = 0, arrow = arrow_style) +
  geom_text_repel(aes(label = column,
                      color = stat_type),
                  size = 3) +
  scale_color_manual(values = c("orange", "green", "brown", "cornflowerblue", "purple")) +
  theme_bw() + 
  theme(legend.position = "bottom")
```

### Linear Regression Model {.tabset}

#### Initial Modeling

```{r initial linear regression}
# Get rid of season and make initial regression plot
salaryAllSeasonsNoCharacterData <- salaryAllSeasonsUpdated %>%
  select(which(sapply(salaryAllSeasons, class) != 'character'))
test_lm_nhl <- lm(cap_hit ~ ., salaryAllSeasonsNoCharacterData)

# Look at what variables have the highest absolute value
nhl_lm_variable_weight_compare <- abs(test_lm_nhl$coefficients)
nhl_lm_variable_weight_compare <- nhl_lm_variable_weight_compare[order(nhl_lm_variable_weight_compare, decreasing = T)]
nhl_lm_variable_weight_compare_names <- nhl_lm_variable_weight_compare %>%
  names() %>% 
  as.data.frame()
colnames(nhl_lm_variable_weight_compare_names) <- "Variable"
nhl_lm_variable_weight_compare_names <- head(nhl_lm_variable_weight_compare_names, 50)
write_rds(nhl_lm_variable_weight_compare_names, file = "RawData/lm_important_names.rds")

# Now look at forwards
salaryAllSeasonsNoCharacterDataForward <- salaryAllSeasonsUpdated %>%
  filter(position == 2) %>% 
  select(which(sapply(salaryAllSeasons, class) != 'character'))
test_lm_nhl <- lm(cap_hit ~ ., salaryAllSeasonsNoCharacterDataForward)
nhl_lm_variable_weight_compare <- abs(test_lm_nhl$coefficients)
nhl_lm_variable_weight_compare <- nhl_lm_variable_weight_compare[order(nhl_lm_variable_weight_compare, decreasing = T)]
nhl_lm_variable_weight_compare_names <- nhl_lm_variable_weight_compare %>%
  names() %>% 
  as.data.frame()
colnames(nhl_lm_variable_weight_compare_names) <- "Variable"
nhl_lm_variable_weight_compare_names <- head(nhl_lm_variable_weight_compare_names, 50)
write_rds(nhl_lm_variable_weight_compare_names, file = "RawData/lm_important_names_forward.rds")

# Now look at defense
salaryAllSeasonsNoCharacterDataForward <- salaryAllSeasonsUpdated %>%
  filter(position == 1) %>% 
  select(which(sapply(salaryAllSeasons, class) != 'character'))
test_lm_nhl <- lm(cap_hit ~ ., salaryAllSeasonsNoCharacterDataForward)
nhl_lm_variable_weight_compare <- abs(test_lm_nhl$coefficients)
nhl_lm_variable_weight_compare <- nhl_lm_variable_weight_compare[order(nhl_lm_variable_weight_compare, decreasing = T)]
nhl_lm_variable_weight_compare_names <- nhl_lm_variable_weight_compare %>%
  names() %>% 
  as.data.frame()
colnames(nhl_lm_variable_weight_compare_names) <- "Variable"
nhl_lm_variable_weight_compare_names <- head(nhl_lm_variable_weight_compare_names, 50)
write_rds(nhl_lm_variable_weight_compare_names, file = "RawData/lm_important_names_defense.rds")
```

Now look at the regression model to see what the leading coefficients are.
```{r linear regression model}
# Look at initial regression coefficients and see which 50 have the most weight
library(broom)
tidy(test_lm_nhl) %>%
  mutate(coef_sign = as.factor(sign(estimate)),
         term = fct_reorder(term, estimate)) %>%
  ggplot(aes(x = term, y = estimate, fill = coef_sign)) +
  geom_bar(stat = "identity", 
           color = "green") +
  scale_fill_manual(values = c("darkred", "darkblue"), 
                    guide = FALSE) +
  coord_flip() + 
  theme_bw()
```

#### Correlation Matrix

Here we can look at how the correlations are connected with each other.
```{r correlation matrix}
# Make correlation matrix for just the all values
library(ggcorrplot)
cor_matrix <- round(cor(salaryAllSeasonsNoCharacterData), 3)
ggcorrplot(cor_matrix, 
           hc.order = TRUE,
           type = "lower",
           lab = TRUE)

# Cluster the similar correlated values
exp_cor_matrix <- cor(salaryAllSeasonsNoCharacterData)
cor_dist_matrix <- 1 - abs(exp_cor_matrix)
cor_dist_matrix <- as.dist(cor_dist_matrix)
library(ggdendro)
nhl_exp_hc <- hclust(cor_dist_matrix,
                     "complete")
ggdendrogram(nhl_exp_hc,
             rotate = T,
             size = 2)
library(dendextend)
cor_dist_matrix %>%
  hclust() %>%
  as.dendrogram() %>%
  set("branches_k_col", 
      k = 5) %>% 
  set("labels_cex", .5) %>%
  ggplot(horiz = TRUE)
```

#### Top Regression Model

Here we examined the RMSE of some different regression models to see which one was the best.
```{r rsme}
# First make function we need to look at RMSE values
set.seed(9)
salaryAllSeasonsNoCharacterData <- salaryAllSeasonsNoCharacterData %>%
  mutate(test_fold = sample(rep(1:5,
                                length.out = n())))

get_cv_preds <- function(model_formula, data) {
  # generate holdout predictions for every row based season
  map_dfr(unique(data$test_fold), 
          function(holdout) {
            # Separate test and training data:
            test_data <- data %>%
              filter(test_fold == holdout)
            train_data <- data %>%
              filter(test_fold != holdout)
            # Train model:
            reg_model <- lm(as.formula(model_formula), data = train_data)
            # Return tibble of holdout results:
            tibble(test_preds = predict(reg_model, newdata = test_data),
                   test_actual = test_data$cap_hit,
                   test_fold = holdout) 
          })
}

# Look at RMSE of different regression models
all_cv_preds <- get_cv_preds(cap_hit ~ ., salaryAllSeasonsNoCharacterData)

salaryAllSeasonsNoCharacterDataJustAll <-
  salaryAllSeasonsNoCharacterData %>%
  select(-c(contains("5on5"),
            contains("5on4"),
            contains("4on5")))
only_contains_all_cv_preds <- get_cv_preds(cap_hit ~ ., salaryAllSeasonsNoCharacterDataJustAll)

salaryAllSeasonsNoCharacterDataNoAll <-
  salaryAllSeasonsNoCharacterData %>%
  select(-contains("all"))
not_contains_all_cv_preds <- get_cv_preds(cap_hit ~ ., salaryAllSeasonsNoCharacterDataNoAll)

int_only_cv_preds <- get_cv_preds(cap_hit ~ 1, salaryAllSeasonsNoCharacterData)

bind_rows(mutate(all_cv_preds, type = "All-Data"),
          mutate(only_contains_all_cv_preds, type = "Just-All-Situations"),
          mutate(not_contains_all_cv_preds, type = "No-All-Situations"),
          mutate(int_only_cv_preds, type = "Intercept-only")) %>%
  group_by(type) %>%
  summarize(rmse = sqrt(mean((test_actual - test_preds)^2))) %>%
  mutate(type = fct_reorder(type, rmse)) %>%
  ggplot(aes(x = type, y = rmse)) +
  geom_point() + 
  coord_flip() + 
  theme_bw()
```

### Lasso/Ridge Regression

```{r initial lasso}
library(stats)
# Change to dummy data set
salaryAllSeasonsSubset <- salaryAllSeasons %>%
  select(-c(player,
            season)) %>%
  filter(games_played >= 20,
         type != "Entry_Level")
# Change to factor data from character
salaryAllSeasonsSubset[sapply(salaryAllSeasonsSubset, is.character)] <- lapply(salaryAllSeasonsSubset[sapply(salaryAllSeasonsSubset, is.character)], as.factor)
# Change to numeric data
salaryAllSeasonsSubset[sapply(salaryAllSeasonsSubset, is.factor)] <- lapply(salaryAllSeasonsSubset[sapply(salaryAllSeasonsSubset, is.factor)], as.numeric)
```

We wanted to show what the ridge plot looks like.
```{r ridge plot}
# Make the needed matrices
model_x <- salaryAllSeasonsSubset %>%
  select(-cap_hit) %>%
  as.matrix()
model_y <- salaryAllSeasonsSubset$cap_hit

# Make the ridge fit plot
library(glmnet)
ridge_fit <- cv.glmnet(model_x, model_y, alpha = 0)
plot(ridge_fit)
```

Also wanted to show the lasso plot.
```{r lasso plot}
lasso_fit <- cv.glmnet(model_x, model_y, alpha = 1)
plot(lasso_fit)
```

Next, we wanted to show how all the models compared. We took the linear regression model and compared it to ridge (which has an alpha level of 0) and increased the alpha by every quartile until it got up to 1 (which is a lasso model). Here we wanted to show which model was the best.
```{r best ridge/lasso model}
# Do comparison of models for holdout performance
set.seed(9)
salaryAllSeasonsSubset <- salaryAllSeasonsSubset %>% mutate(test_fold = sample(rep(1:5, length.out = n())))
library(purrr)
holdout_predictions <- 
  map_dfr(unique(salaryAllSeasonsSubset$test_fold), 
          function(holdout) {
            # Separate test and training data:
            test_data <- salaryAllSeasonsSubset %>% filter(test_fold == holdout)
            train_data <- salaryAllSeasonsSubset %>% filter(test_fold != holdout)
            # Repeat for matrices
            test_x <- as.matrix(dplyr::select(test_data, -cap_hit))
            train_x <- as.matrix(dplyr::select(train_data, -cap_hit))
            # Train models:
            lm_model <- lm(cap_hit ~ ., data = train_data)
            ridge_model <- cv.glmnet(train_x, train_data$cap_hit, alpha = 0)
            lasso_model <- cv.glmnet(train_x, train_data$cap_hit, alpha = 1)
            en_model <- cv.glmnet(train_x, train_data$cap_hit, alpha = .5)
            quarter_model <- cv.glmnet(train_x, train_data$cap_hit, alpha = .25)
            three_quarter_model <- cv.glmnet(train_x, train_data$cap_hit, alpha = .75)
            # Return tibble of holdout results:
            tibble(lm_preds = predict(lm_model, newdata = test_data),
                   ridge_preds = as.numeric(predict(ridge_model, newx = test_x)),
                   lasso_preds = as.numeric(predict(lasso_model, newx = test_x)),
                   en_preds = as.numeric(predict(en_model, newx = test_x)),
                   quarter_preds = as.numeric(predict(quarter_model, newx = test_x)),
                   three_quarter_preds = as.numeric(predict(three_quarter_model, newx = test_x)),
                   test_actual = test_data$cap_hit, test_fold = holdout) 
          })

# Compute the RMSE across folds with standard error intervals
holdout_predictions %>%
  pivot_longer(lm_preds:three_quarter_preds, 
               names_to = "type", values_to = "test_preds") %>%
  group_by(type, test_fold) %>%
  summarize(rmse =
              sqrt(mean((test_actual - test_preds) ** 2))) %>% 
  ggplot(aes(x = type, y = rmse)) + 
  geom_point() + theme_bw() +
  stat_summary(fun = mean, geom = "point", 
               color = "red") + 
  stat_summary(fun.data = mean_se, geom = "errorbar",
               color = "red")
```

```{r most important variables lasso}
# Find the most important variables
library(glmnet)
best_lambda <- lasso_fit$lambda.min
best_model <- glmnet(model_x, model_y, alpha = 1, lambda = best_lambda)
importantLassoNames <- names(best_model$beta[, 1][best_model$beta[, 1] != 0])
saveRDS(importantLassoNames, file = "RawData/lasso_important_names.rds")


# Forward Lasso Model -----------------------------------------------------

# Make the needed matrices
salaryAllSeasonsSubsetForward <- salaryAllSeasonsSubset%>%
  filter(position == 2)
model_x <- salaryAllSeasonsSubsetForward %>%
  select(-cap_hit) %>%
  as.matrix()
model_y <- salaryAllSeasonsSubsetForward$cap_hit

# Make the lasso fit plot
library(glmnet)
lasso_fit <- cv.glmnet(model_x, model_y, alpha = 1)

# Find the most important variables
library(glmnet)
best_lambda <- lasso_fit$lambda.min
best_model <- glmnet(model_x, model_y, alpha = 1, lambda = best_lambda)
importantLassoNames <- names(best_model$beta[, 1][best_model$beta[, 1] != 0])
saveRDS(importantLassoNames, file = "RawData/lasso_important_names_forward.rds")


# Defense Lasso Model -----------------------------------------------------

# Make the needed matrices
salaryAllSeasonsSubsetDefense <- salaryAllSeasonsSubset%>%
  filter(position == 1)
model_x <- salaryAllSeasonsSubsetDefense %>%
  select(-cap_hit) %>%
  as.matrix()
model_y <- salaryAllSeasonsSubsetDefense$cap_hit

# Make the lasso fit plot
library(glmnet)
lasso_fit <- cv.glmnet(model_x, model_y, alpha = 1)

# Find the most important variables
library(glmnet)
best_lambda <- lasso_fit$lambda.min
best_model <- glmnet(model_x, model_y, alpha = 1, lambda = best_lambda)
importantLassoNames <- names(best_model$beta[, 1][best_model$beta[, 1] != 0])
saveRDS(importantLassoNames, file = "RawData/lasso_important_names_defense.rds")
```

### Random Forest

Here we wanted to show a plot of the top 100 most important variables in this type of dimension reduction technique.
```{r random forest plot all}
set.seed(9)
library(ranger)
randomNHLRegression <- ranger(cap_hit ~ .,
                              salaryAllSeasonsSubset,
                              importance = "impurity",
                              mtry = ncol(salaryAllSeasonsSubset) / 3)

# Find the variable importance
library(vip)
vip(randomNHLRegression,
    geom = "col",
    num_features = 76L) +
  theme_bw()

# Table of the most important variables
vi_scores <- vi(randomNHLRegression,
                sort = T,
                decreasing = T,
                rank = T) %>%
  top_n(-50)
```

We did the same thing subsetting the data by forwards.
```{r random forest plot forward}
salaryAllSeasonsSubsetForward <- salaryAllSeasonsSubset %>%
  filter(position == 2) %>%
  select(-position)

set.seed(9)
randomNHLRegressionForward <- ranger(cap_hit ~ .,
                              salaryAllSeasonsSubsetForward,
                              importance = "impurity",
                              mtry = ncol(salaryAllSeasonsSubsetForward) / 3)

vip(randomNHLRegressionForward,
    geom = "col",
    num_features = 76L) +
  theme_bw()

vi_scoresForward <- vi(randomNHLRegressionForward,
                sort = T,
                decreasing = T,
                rank = T) %>%
  top_n(-50)
```

And lastly did the same random forest technique subsetting it by defense.
```{r random forest plot defense}
salaryAllSeasonsSubsetDefense <- salaryAllSeasonsSubset %>%
  filter(position == 1) %>%
  select(-position)

set.seed(9)
randomNHLRegressionDefense <- ranger(cap_hit ~ .,
                                     salaryAllSeasonsSubsetDefense,
                                     importance = "impurity",
                                     mtry = ncol(salaryAllSeasonsSubsetDefense) / 3)

vip(randomNHLRegressionDefense,
    geom = "col",
    num_features = 76L) +
  theme_bw()

vi_scoresDefense <- vi(randomNHLRegressionDefense,
                       sort = T,
                       decreasing = T,
                       rank = T) %>%
  top_n(-50)
```

### Trying to find the most important variables

By having these different plots, we tried to see if we could find a pattern somewhere that would give us the most important variables to use in our reduction.

We first looked at the all data, without subsetting by position.
```{r reduction best variables}
# See what variables show up the most for whole dataset and position data
importantLassoNames <- readRDS("RawData/lasso_important_names.rds")
importantLmNames <- readRDS("RawData/lm_important_names.rds")
importantLassoNames <- as.data.frame(importantLassoNames) %>%
  rename(Variable = importantLassoNames)

# All data
knownNames <- rbind(as.tibble(importantLassoNames$Variable),
                    as.tibble(vi_scores$Variable),
                    as.tibble(importantLmNames$Variable))

mostImportantVariables <- knownNames %>%
  count(value) %>%
  arrange(desc(n))
mostImportantVariables
```

We then did the same doing by forwards.
```{r reduction best variables forward}
# Forward Data
importantLassoNamesForward <- readRDS("RawData/lasso_important_names_forward.rds")
importantLmNamesForward <- readRDS("RawData/lm_important_names_forward.rds")
importantLassoNamesForward <- as.data.frame(importantLassoNamesForward) %>%
  rename(Variable = importantLassoNamesForward)
knownNamesForward <- rbind(as.tibble(importantLassoNamesForward$Variable),
                    as.tibble(vi_scoresForward$Variable),
                    as.tibble(importantLmNamesForward$Variable))
mostImportantVariablesForward <- knownNamesForward %>%
  count(value) %>%
  arrange(desc(n))
mostImportantVariablesForward
```

And lastly looked at the defensive players.
```{r reduction best variables defense}
# Defense Data
importantLassoNamesDefense <- readRDS("RawData/lasso_important_names_defense.rds")
importantLmNamesDefense <- readRDS("RawData/lm_important_names_defense.rds")
knownNamesDefense <- rbind(as.tibble(importantLassoNamesForward$Variable),
                           as.tibble(vi_scoresDefense$Variable),
                           as.tibble(importantLmNamesDefense$Variable))
mostImportantVariablesDefense <- knownNamesDefense %>%
  count(value) %>%
  arrange(desc(n))
mostImportantVariablesDefense
```

By using random forest, we could look at what the model says is the optimal number of predictors we should end up using.
```{r predictor number plot}
# Tune the random forests
library(caret)
rf_tune_grid <- 
  expand.grid(mtry = seq(3, 75, by = 3), 
              splitrule = "variance",
              min.node.size = 5)
set.seed(9)
caret_nhl_rf <- 
  train(cap_hit ~ ., 
        data = salaryAllSeasonsSubset,
        method = "ranger", 
        num.trees = 75,
        trControl = trainControl(method = "cv", number = 5),
        tuneGrid = rf_tune_grid)
ggplot(caret_nhl_rf) + theme_bw()
```